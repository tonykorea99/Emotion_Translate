import os
import random
import re
import json
import numpy as np
import torch
import pandas as pd
from torch.utils.data import DataLoader
from collections import Counter

# ---------------------------------------------------------
# [ì¤‘ìš”] ì‹œìŠ¤í…œ ì„¤ì •
# ---------------------------------------------------------
os.environ["TOKENIZERS_PARALLELISM"] = "false"
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"

# [!!! ì¤‘ìš” !!!] W&B API Key ì„¤ì •
os.environ["WANDB_API_KEY"] = "e758b93c3e805dafd9d187ec1c0b1b984fe6256f"

from datasets import Dataset, DatasetDict, load_dataset, concatenate_datasets
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification, 
    DataCollatorWithPadding,
    get_linear_schedule_with_warmup, 
    AutoModelForSeq2SeqLM 
)
from sklearn.metrics import accuracy_score, recall_score, f1_score
import wandb

# ---------------------------------------------------------
# 1. ì„¤ì • ë° í•˜ì´í¼íŒŒë¼ë¯¸í„°
# ---------------------------------------------------------
WRIME_URL = "https://raw.githubusercontent.com/ids-cv/wrime/master/wrime-ver1.tsv"
CSV_PATHS = [
    "/home/hail/emotionproject/datasets/jvnv_v1/transcription.csv",
    "/home/hail/emotionproject/datasets/japanese_emotions.csv",
]

# JSONL ì €ì¥ ê²½ë¡œ (ê²°ê³¼ í™•ì¸ìš© - ìš©ëŸ‰ ì‘ìŒ)
JSONL_DIR = "./wrime_jsonl_jp_bert"

# ëª¨ë¸ ì„¤ì •
MODEL_NAME = "cl-tohoku/bert-base-japanese-v3"   
M2M_MODEL_NAME = "facebook/m2m100_418M" # í…ŒìŠ¤íŠ¸ìš©

EMO_LABELS = [
    "Joy", "Sadness", "Anticipation", "Surprise", 
    "Anger", "Fear", "Disgust", "Trust"
]
id2label = {i: lab for i, lab in enumerate(EMO_LABELS)}
label2id = {lab: i for i, lab in id2label.items()}

# í•˜ì´í¼íŒŒë¼ë¯¸í„°
BATCH_SIZE = 32       
EVAL_BATCH_SIZE = 64  
LR = 2e-5             
NUM_EPOCHS = 3        # 3 ì—í­ ê³ ì •
MAX_LEN = 128
SEED = 42
LOG_INTERVAL = 10        
VALIDATION_INTERVAL = 100 

# W&B ì„¤ì •
WANDB_ENTITY = "hails"
WANDB_PROJECT = "Emotional_Traslate_Bert_m2m100"
WANDB_RUN_NAME = "JP_BERT_Direct_NoSave_Epoch3" 

# ---------------------------------------------------------
# 2. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ---------------------------------------------------------
def set_seed(seed: int = 42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)

def compute_metrics_detailed(all_labels: list, all_preds: list) -> dict:
    y_true = np.array(all_labels)
    y_pred = np.array(all_preds)

    overall_acc = accuracy_score(y_true, y_pred)
    f1_macro = f1_score(y_true, y_pred, average="macro")
    
    num_labels = len(EMO_LABELS)
    per_class_recall = recall_score(
        y_true,
        y_pred,
        labels=list(range(num_labels)),
        average=None,
        zero_division=0.0,
    )

    result = {
        "overall_accuracy": overall_acc,
        "f1_macro": f1_macro,
        "per_class_recall": {
            id2label[i]: float(per_class_recall[i]) for i in range(num_labels)
        },
    }
    return result

# ---------------------------------------------------------
# 3. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
# ---------------------------------------------------------
def process_csv_data(csv_paths: list) -> DatasetDict:
    all_datasets = []
    RAW_TO_EMO_MAP = {
        "happy": "Joy", "sad": "Sadness", "anger": "Anger", "fear": "Fear", 
        "disgust": "Disgust", "surprise": "Surprise", 
        "joy": "Joy", "sadness": "Sadness", "anticipation": "Anticipation", 
        "trust": "Trust",
    }

    for path in csv_paths:
        if not os.path.exists(path): continue
        try: df = pd.read_csv(path)
        except: continue
        
        if 'transcription.csv' in path: 
            df = df.rename(columns={'text': 'Sentence_std', 'emotion_label': 'raw_label'})
        elif 'japanese_emotions.csv' in path: 
            df = df.rename(columns={'tweet': 'Sentence_std', 'sentiment': 'raw_label'})
        
        if 'Sentence_std' in df.columns and 'raw_label' in df.columns:
            def map_and_filter(row):
                raw = str(row['raw_label']).strip().lower()
                mapped_label = RAW_TO_EMO_MAP.get(raw, None)
                if mapped_label in EMO_LABELS:
                    row['labels'] = label2id[mapped_label]
                    return row
                return None 
            
            df = df[['Sentence_std', 'raw_label']].copy()
            ds = Dataset.from_pandas(df)
            ds = ds.map(map_and_filter, remove_columns=['raw_label'])
            ds = ds.filter(lambda x: x.get('labels') is not None and x.get('Sentence_std') is not None)
            if len(ds) > 0: all_datasets.append(ds)

    if not all_datasets:
        empty_ds = Dataset.from_dict({"Sentence_std": [], "labels": []})
        return DatasetDict({"validation_csv": empty_ds, "test_csv": empty_ds})

    full_csv_ds = concatenate_datasets(all_datasets)
    split_ds = full_csv_ds.train_test_split(test_size=0.5, seed=SEED)
    return DatasetDict({"validation_csv": split_ds["train"], "test_csv": split_ds["test"]})


def prepare_datasets(csv_paths: list):
    """
    [ìˆ˜ì •] ë””ìŠ¤í¬ ì €ì¥(ìºì‹±) ì—†ì´ ë©”ëª¨ë¦¬ì—ì„œë§Œ ì²˜ë¦¬
    """
    print("\n[Data] WRIME ë° ì™¸ë¶€ ë°ì´í„° ë¡œë“œ ì¤‘...")
    
    # 1. WRIME ë¡œë“œ
    raw_wrime = load_dataset("csv", data_files=WRIME_URL, delimiter="\t")["train"]
    WRIME_SCORE_COLS = [f"Writer_{e}" for e in EMO_LABELS]
    
    def wrime_process(ex):
        scores = [ex[c] for c in WRIME_SCORE_COLS]
        ex["labels"] = int(np.argmax(scores)) 
        ex["Sentence_std"] = ex.get("Sentence", "")
        return ex

    raw_wrime = raw_wrime.map(wrime_process)
    
    wrime_splits = {
        "train": raw_wrime.filter(lambda x: x["Train/Dev/Test"]=="train"),
        "validation": raw_wrime.filter(lambda x: x["Train/Dev/Test"]=="dev"),
        "test": raw_wrime.filter(lambda x: x["Train/Dev/Test"]=="test")
    }
    
    for split in wrime_splits:
        wrime_splits[split] = wrime_splits[split].select_columns(["Sentence_std", "labels"])
    
    # 2. CSV ë¡œë“œ
    csv_splits = process_csv_data(csv_paths)
    
    # 3. í•©ì¹˜ê¸°
    dataset = DatasetDict({
        "train": wrime_splits["train"],
        "validation": concatenate_datasets([wrime_splits["validation"], csv_splits["validation_csv"]]),
        "test": concatenate_datasets([wrime_splits["test"], csv_splits["test_csv"]])
    })

    print(f" -> Train: {len(dataset['train'])} | Val: {len(dataset['validation'])} | Test: {len(dataset['test'])}")

    # 4. í† í°í™”
    print(f"\n[Tokenizer] ì¼ë³¸ì–´ BERT í† í¬ë‚˜ì´ì € ì ìš©: {MODEL_NAME}")
    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)

    def tokenize_function(examples):
        return tokenizer(
            examples["Sentence_std"],
            padding="max_length",
            truncation=True,
            max_length=MAX_LEN
        )

    tokenized_datasets = dataset.map(tokenize_function, batched=True)
    tokenized_datasets.set_format(type="torch", columns=["input_ids", "attention_mask", "labels"])
    
    # ğŸŸ¢ [ìˆ˜ì •] save_to_disk ì œê±°ë¨ (ì„œë²„ ë¶€ë‹´ X)
    
    return tokenized_datasets, tokenizer

# ---------------------------------------------------------
# 4. í‰ê°€ í•¨ìˆ˜
# ---------------------------------------------------------
def evaluate(model, dataloader, device, split_name, global_step):
    model.eval()
    total_loss = 0.0
    total_examples = 0
    all_labels, all_preds = [], []

    with torch.no_grad():
        for batch_idx, batch in enumerate(dataloader):
            batch = {k: v.to(device) for k, v in batch.items()}
            outputs = model(**batch)
            loss = outputs.loss
            logits = outputs.logits
            labels = batch["labels"]

            wandb.log({f"{split_name}/loss_batch": loss.item(), f"{split_name}/batch_idx": batch_idx}, step=global_step)

            total_loss += loss.item() * labels.size(0)
            total_examples += labels.size(0)
            preds = torch.argmax(logits, dim=-1)
            
            all_labels.extend(labels.cpu().tolist())
            all_preds.extend(preds.cpu().tolist())

    if total_examples == 0: return 0.0, 0.0, {}
    
    avg_loss = total_loss / total_examples
    metrics = compute_metrics_detailed(all_labels, all_preds)
    
    log_dict = {
        f"{split_name}/loss_epoch": avg_loss,
        f"{split_name}/accuracy": metrics["overall_accuracy"],
        f"{split_name}/f1_macro": metrics["f1_macro"],
    }
    for emo_name, acc in metrics["per_class_recall"].items():
        log_dict[f"{split_name}/acc_{emo_name}"] = acc

    wandb.log(log_dict, step=global_step)
    
    model.train() 
    return avg_loss, metrics["overall_accuracy"], metrics["per_class_recall"]

# ---------------------------------------------------------
# 5. ë©”ì¸ í•¨ìˆ˜
# ---------------------------------------------------------
def main():
    set_seed(SEED)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"[Main] Device: {device}")

    wandb.init(
        entity=WANDB_ENTITY,
        project=WANDB_PROJECT,
        name=WANDB_RUN_NAME,
        config={
            "architecture": "JP BERT Direct (No Save)", 
            "model": MODEL_NAME,
            "batch_size": BATCH_SIZE, 
            "lr": LR, 
            "epochs": NUM_EPOCHS
        },
    )

    # ë°ì´í„° ì¤€ë¹„ (ì €ì¥ ì—†ì´ ë©”ëª¨ë¦¬ ë¡œë“œ)
    tokenized_datasets, tokenizer = prepare_datasets(CSV_PATHS)
    
    data_collator = DataCollatorWithPadding(tokenizer)
    train_loader = DataLoader(tokenized_datasets["train"], batch_size=BATCH_SIZE, shuffle=True, collate_fn=data_collator, num_workers=4, pin_memory=True)
    val_loader = DataLoader(tokenized_datasets["validation"], batch_size=EVAL_BATCH_SIZE, shuffle=False, collate_fn=data_collator, num_workers=4)
    test_loader = DataLoader(tokenized_datasets["test"], batch_size=EVAL_BATCH_SIZE, shuffle=False, collate_fn=data_collator, num_workers=4)

    # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°
    print("\n[Main] í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°...")
    train_labels = np.array(tokenized_datasets["train"]["labels"])
    class_counts = Counter(train_labels)
    total_samples = len(train_labels)
    num_classes = len(EMO_LABELS)

    weights = []
    for i in range(num_classes):
        count = class_counts.get(i, 0)
        w = total_samples / (num_classes * count) if count > 0 else 1.0
        weights.append(w)
    
    class_weights = torch.tensor(weights, dtype=torch.float).to(device)
    loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights)
    print(f" -> Class Weights: {weights}")

    # ëª¨ë¸ ë¡œë“œ
    print(f"\n[Main] ì¼ë³¸ì–´ BERT ëª¨ë¸ ë¡œë“œ: {MODEL_NAME}")
    model = AutoModelForSequenceClassification.from_pretrained(
        MODEL_NAME, 
        num_labels=len(EMO_LABELS), 
        id2label=id2label, 
        label2id=label2id
    )
    model.to(device)

    # í•™ìŠµ ì„¤ì •
    optimizer = torch.optim.AdamW(model.parameters(), lr=LR)
    total_steps = len(train_loader) * NUM_EPOCHS
    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(total_steps * 0.1), num_training_steps=total_steps)
    
    global_step = 0
    final_model_path = "./JP_BERT_Epoch3_Final" # ìµœì¢… ëª¨ë¸ë§Œ ë”± í•œë²ˆ ì €ì¥

    print(f"\n[Main] í•™ìŠµ ì‹œì‘... (Epochs: {NUM_EPOCHS})")

    for epoch in range(NUM_EPOCHS):
        model.train()
        epoch_loss = 0.0
        epoch_examples = 0
        all_train_labels, all_train_preds = [], []

        for batch_idx, batch in enumerate(train_loader):
            batch = {k: v.to(device) for k, v in batch.items()}
            labels = batch["labels"]

            outputs = model(**batch)
            loss = loss_fn(outputs.logits, labels)

            optimizer.zero_grad()
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            optimizer.step()
            scheduler.step()

            epoch_loss += loss.item() * labels.size(0)
            epoch_examples += labels.size(0)
            preds = torch.argmax(outputs.logits, dim=-1)
            
            all_train_labels.extend(labels.cpu().tolist())
            all_train_preds.extend(preds.cpu().tolist())

            wandb.log({"train/loss": loss.item(), "train/lr": scheduler.get_last_lr()[0]}, step=global_step)
            
            if global_step % LOG_INTERVAL == 0:
                print(f"   [Epoch {epoch+1}] Step {global_step}/{total_steps} | Loss: {loss.item():.4f} | LR: {scheduler.get_last_lr()[0]:.8f}")
            
            if global_step > 0 and global_step % VALIDATION_INTERVAL == 0:
                val_loss, val_acc, _ = evaluate(model, val_loader, device, "val", global_step)
                print(f"   >>> [Validation] Loss: {val_loss:.4f}, Acc: {val_acc:.4f}")

            global_step += 1

        train_loss_epoch = epoch_loss / epoch_examples
        metrics = compute_metrics_detailed(all_train_labels, all_train_preds)
        
        log_dict = {"train/loss_epoch": train_loss_epoch, "train/accuracy": metrics["overall_accuracy"], "train/epoch_end": epoch}
        wandb.log(log_dict, step=global_step)

        print(f"[Epoch {epoch+1}] Train Loss: {train_loss_epoch:.4f}, Acc: {metrics['overall_accuracy']:.4f}")
        
        val_loss, val_acc, _ = evaluate(model, val_loader, device, "val", global_step)
        print(f"[Epoch {epoch+1}] Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}")

    print("\n[Main] í•™ìŠµ ì¢…ë£Œ. ìµœì¢… ëª¨ë¸ë§Œ ì €ì¥í•©ë‹ˆë‹¤.")
    model.save_pretrained(final_model_path)
    tokenizer.save_pretrained(final_model_path)

    print("\n[Main] ìµœì¢… í…ŒìŠ¤íŠ¸ í‰ê°€...")
    test_loss, test_acc, _ = evaluate(model, test_loader, device, "test", global_step)
    print(f"[TEST] Loss: {test_loss:.4f}, Acc: {test_acc:.4f}")

    wandb.finish()

    # ---------------------------------------------------------
    # 6. ì‹¤ì‹œê°„ í…ŒìŠ¤íŠ¸ (í•œêµ­ì–´ ì§€ì›ì„ ìœ„í•œ M2M + JP BERT)
    # ---------------------------------------------------------
    print("\n--- ì‹¤ì‹œê°„ ê°ì • ë¶„ì„ í…ŒìŠ¤íŠ¸ (JP Model) ---")
    print(" * M2M100 ë²ˆì—­ê¸° ë¡œë“œ ì¤‘ (í•œêµ­ì–´ ì…ë ¥ ëŒ€ì‘ìš©)...")
    m2m_tokenizer = AutoTokenizer.from_pretrained(M2M_MODEL_NAME, src_lang="ko")
    m2m_model = AutoModelForSeq2SeqLM.from_pretrained(M2M_MODEL_NAME).to(device)
    m2m_model.eval()
    
    model.eval()
    
    RE_KOREAN = re.compile(r'[ê°€-í£]')

    while True:
        try:
            print("\ní•œêµ­ì–´ ë˜ëŠ” ì¼ë³¸ì–´ ë¬¸ì¥ì„ ì…ë ¥í•˜ì„¸ìš”. (ì¢…ë£Œ: '0')")
            input_text = input(" [ì…ë ¥] > ").strip()
            if input_text == "0": break
            if not input_text: continue

            final_input_text = input_text
            
            if RE_KOREAN.search(input_text):
                print(" [ê°ì§€] í•œêµ­ì–´ -> ì¼ë³¸ì–´ ë²ˆì—­ ì¤‘...")
                m2m_tokenizer.src_lang = "ko"
                m2m_inputs = m2m_tokenizer(input_text, return_tensors="pt").to(device)
                with torch.no_grad():
                    gen_tokens = m2m_model.generate(**m2m_inputs, forced_bos_token_id=m2m_tokenizer.get_lang_id("ja"))
                final_input_text = m2m_tokenizer.decode(gen_tokens[0], skip_special_tokens=True)
                print(f" [ë²ˆì—­ëœ ì¼ë³¸ì–´] {final_input_text}")
            else:
                print(" [ê°ì§€] ì¼ë³¸ì–´ (ì§ì ‘ ì…ë ¥)")

            inputs = tokenizer(final_input_text, return_tensors="pt", truncation=True, max_length=MAX_LEN).to(device)
            with torch.no_grad():
                logits = model(**inputs).logits
            
            pred_id = torch.argmax(logits, dim=-1).item()
            print(f" [ì˜ˆì¸¡ ê°ì •] {id2label[pred_id]}")

        except Exception as e:
            print(f"ì˜¤ë¥˜: {e}")
            break

if __name__ == "__main__":
    main()